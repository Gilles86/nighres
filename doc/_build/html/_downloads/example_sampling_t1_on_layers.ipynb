{
  "nbformat_minor": 0, 
  "nbformat": 4, 
  "cells": [
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "%matplotlib inline"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "\nSampling T1 at different intracortical depths\n==============================================\n\nThis example shows a complete pipeline performing all steps necessary to use\nMP2RAGE data for sampling T1 at different intracortical depth levels,\ndetermined using a volume-preserving approach :\n\n* Dowloading openly available MP2RAGE data [1]_\n* Skull stripping :func:`nighres.brain.mp2rage_skullstripping`\n* Tissue segmentation using MGDM :func:`nighres.brain.mgdm_segmentation` [2]_\n* Creating levelset representations of the pial and white matter surface\n  :func:`nighres.surface.probability_to_levelset`\n* Equivolumetric layering of the cortical sheet\n  :func:`nighres.laminar.volumetric_layering` [3]_\n* Sampling T1 on the different intracortical depth\n  :func:`nighres.laminar.profile_sampling`\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "source": [
        "Import and download\n~~~~~~~~~~~~~~~~~~~\nFirst we import nighres and the os module to set the output directory and\nfilenames for the files we will download. Make sure to run this file in a\ndirectory you have write-access to, or change the out_dir variable below.\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "import nighres\nimport os\n\nout_dir = os.paht.join(os.getcwd(), 'nighres_examples/t1_sampling')\nt1map = os.path.join(out_dir, \"T1map.nii.gz\")\nt1w = os.path.join(out_dir, \"T1w.nii.gz\")"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Now we download an example MP2RAGE dataset from the\nCBS Open Science repository\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "nighres.download_from_url(\"http://openscience.cbs.mpg.de/bazin/7T_Quantitative/MP2RAGE-05mm/subject01_mp2rage_0p5iso_qT1.nii.gz\",\n                          t1map)\nnighres.download_from_url(\"http://openscience.cbs.mpg.de/bazin/7T_Quantitative/MP2RAGE-05mm/subject01_mp2rage_0p5iso_uni.nii.gz\",\n                          t1w)\n\n# TODO: also download INV2, for now using local version\ninv2 = '/SCR/data/cbstools_testing/7t_trt/test_nii/INV2.nii.gz'"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Tissue classification\n~~~~~~~~~~~~~~~~~~~~~~\nThe first processing step is to skullstrip the images. Only the second\ninversion image is required to calculate the brain mask. But if we input\nthe T1map and T1w image as well, they will be masked for us.\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "skullstripping_results = nighres.brain.mp2rage_skullstripping(\n                                                        second_inversion=inv2,\n                                                        t1_weighted=t1w,\n                                                        t1_map=t1map,\n                                                        save_data=True,\n                                                        output_dir=out_dir)"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        ".. tip:: in Nighres, functions that have several outputs return a\n   dictionary storing the different outputs. You can find the keys in the\n   docstring or list them like this:\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "skullstripping_results.keys()"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Next we use the masked data as input for tissue segmentation with the MGDM\nalgorithm. The segmentation works with a single contrast, but can  be\nimproved with additional contrasts. In this case we use the T1-weigthed\nimage as well as the quantitative T1map.\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "segmentation_results = nighres.brain.mgdm_segmentation(\n                        contrast_image1=skullstripping_results['t1w_masked'],\n                        contrast_type1=\"Mp2rage7T\",\n                        contrast_image2=skullstripping_results['t1map_masked'],\n                        contrast_type2=\"T1map7T\",\n                        save_data=True, output_dir=out_dir)"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Creating surfaces\n~~~~~~~~~~~~~~~~~\nTo create levelset representations of the pial and white matter surface,\nwe first use the segmentation results to create binary masks representing\nthose boundaries.\n\n.. tip:: Since data is passed as Nibabel objects, we can manipulate it\n   directly in Python, without ever saving or reloading the data\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "import numpy as np\nimport nibabel as nb\n\n# TODO: this needs explanation\nwm = [11, 12, 13, 17, 18, 30, 31, 32, 33, 34, 35, 36, 37,\n      38, 39, 40, 41, 47, 48]\ngm = [26, 27]\n\nsegmentation = segmentation_results['segmentation'].get_data()\nwm_mask = np.zeros(segmentation.shape)\nfor x in wm:\n    wm_mask[np.where(segmentation == x)] = 1\nwm_nii = nb.Nifti1Image(wm_mask,\n                        segmentation_results['segmentation'].get_affine())\n\ngm_mask = np.copy(wm_mask)\nfor x in gm:\n    gm_mask[np.where(segmentation == x)] = 1\ngm_nii = nb.Nifti1Image(gm_mask,\n                        segmentation_results['segmentation'].get_affine())"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Now we use Nighres again to create the levelsets from the binary masks\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "gm_wm_levelset = nighres.surface.probability_to_levelset(\n                                                    probability_image=wm_nii,\n                                                    save_data=True,\n                                                    output_dir=out_dir)\ngm_csf_levelset = nighres.surface.probability_to_levelset(\n                                                    probability_image=gm_nii,\n                                                    save_data=True,\n                                                    output_dir=out_dir)"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Creating layers and sampling\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nOnce we have the levelset representations of the pial and white matter\nsurface we can perform volume-preserving layering of the space between the\ntwo surfaces. Here we choose only 3 layers to save time.\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "layering_results = nighres.laminar.volumetric_layering(\n                                                inner_levelset=gm_wm_levelset,\n                                                outer_levelset=gm_csf_levelset,\n                                                n_layers=3,\n                                                save_data=True,\n                                                output_dir=out_dir)"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Finally, we use the intracortical layers, represented as levelsets,\nto sample T1 across the different cortical depth levels\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "profiles = nighres.laminar.profile_sampling(\n                        profile_surface_image=layering_results['boundaries'],\n                        intensity_image=t1map,\n                        save_data=True,\n                        output_dir=out_dir)\n\n\n# TODO: Visualize data using Nilearn"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "References\n~~~~~~~~~~~\n.. [1] Tardif et al (2016). Open Science CBS Neuroimaging Repository: Sharing\n   ultra-high-field MR images of the brain.\n   DOI: 10.1016/j.neuroimage.2015.08.042\n.. [2] Bogovic, Prince and Bazin (2013). A multiple object geometric\n   deformable model for image segmentation. DOI: 10.1016/j.cviu.2012.10.006.A\n.. [3] Waehnert et al (2014). Anatomically motivated modeling of cortical\n   laminae. DOI: 10.1016/j.neuroimage.2013.03.078\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }
  ], 
  "metadata": {
    "kernelspec": {
      "display_name": "Python 2", 
      "name": "python2", 
      "language": "python"
    }, 
    "language_info": {
      "mimetype": "text/x-python", 
      "nbconvert_exporter": "python", 
      "name": "python", 
      "file_extension": ".py", 
      "version": "2.7.12", 
      "pygments_lexer": "ipython2", 
      "codemirror_mode": {
        "version": 2, 
        "name": "ipython"
      }
    }
  }
}